"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1647],{3905:function(e,a,t){t.d(a,{Zo:function(){return m},kt:function(){return h}});var n=t(7294);function i(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function l(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){i(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function o(e,a){if(null==e)return{};var t,n,i=function(e,a){if(null==e)return{};var t,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||(i[t]=e[t]);return i}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var s=n.createContext({}),p=function(e){var a=n.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):l(l({},a),e)),t},m=function(e){var a=p(e.components);return n.createElement(s.Provider,{value:a},e.children)},u={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},c=n.forwardRef((function(e,a){var t=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=p(t),h=i,f=c["".concat(s,".").concat(h)]||c[h]||u[h]||r;return t?n.createElement(f,l(l({ref:a},m),{},{components:t})):n.createElement(f,l({ref:a},m))}));function h(e,a){var t=arguments,i=a&&a.mdxType;if("string"==typeof e||i){var r=t.length,l=new Array(r);l[0]=c;var o={};for(var s in a)hasOwnProperty.call(a,s)&&(o[s]=a[s]);o.originalType=e,o.mdxType="string"==typeof e?e:i,l[1]=o;for(var p=2;p<r;p++)l[p]=t[p];return n.createElement.apply(null,l)}return n.createElement.apply(null,t)}c.displayName="MDXCreateElement"},1825:function(e,a,t){t.r(a),t.d(a,{assets:function(){return m},contentTitle:function(){return s},default:function(){return h},frontMatter:function(){return o},metadata:function(){return p},toc:function(){return u}});var n=t(7462),i=t(3366),r=(t(7294),t(3905)),l=["components"],o={sidebar_position:6},s=void 0,p={unversionedId:"AI4Science/bayesianInference",id:"AI4Science/bayesianInference",title:"bayesianInference",description:"3.4. Bayesian Inference",source:"@site/docs/AI4Science/bayesianInference.md",sourceDirName:"AI4Science",slug:"/AI4Science/bayesianInference",permalink:"/MathEpiDeepLearning/docs/AI4Science/bayesianInference",editUrl:"https://github.com/JuliaEpi/MathEpiDeepLearning/docs/AI4Science/bayesianInference.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"optimization",permalink:"/MathEpiDeepLearning/docs/AI4Science/optimization"},next:{title:"numericalanalysis",permalink:"/MathEpiDeepLearning/docs/AI4Science/numericalanalysis"}},m={},u=[{value:'<span id="head30">3.4. Bayesian Inference</span>',id:"34-bayesian-inference",level:2},{value:'<span id="head31">3.4.1. MCMC</span>',id:"341-mcmc",level:3},{value:'<span id="head32">3.4.2. Approximate Bayesian Computation (ABC)</span>',id:"342-approximate-bayesian-computation-abc",level:3},{value:'<span id="head33">3.4.3. Data Assimilation (SMC, particles filter)</span>',id:"343-data-assimilation-smc-particles-filter",level:3},{value:'<span id="head34">3.4.4. Variational Inference</span>',id:"344-variational-inference",level:3},{value:'<span id="head35">3.4.5. Gaussion, non-Gaussion and Kernel</span>',id:"345-gaussion-non-gaussion-and-kernel",level:3},{value:'<span id="head36">3.4.6. Bayesian Optimization</span>',id:"346-bayesian-optimization",level:3},{value:'<span id="head37">3.4.7. Information theory</span>',id:"347-information-theory",level:3},{value:'<span id="head38">3.4.8. Uncertainty</span>',id:"348-uncertainty",level:3},{value:'<span id="head39">3.4.9. Casual</span>',id:"349-casual",level:3},{value:'<span id="head40">3.4.10. Sampling</span>',id:"3410-sampling",level:3},{value:"3.4.11 Message Passing",id:"3411-message-passing",level:3}],c={toc:u};function h(e){var a=e.components,t=(0,i.Z)(e,l);return(0,r.kt)("wrapper",(0,n.Z)({},c,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"34-bayesian-inference"},(0,r.kt)("span",{id:"head30"},"3.4. Bayesian Inference")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/StatisticalRethinkingJulia"},"StatisticalRethinkingJulia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/StanJulia"},"StanJulia")),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/TuringLang"},"The Turing Language")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/cscherrer/Soss.jl"},"cscherrer/Soss.jl: Probabilistic programming via source rewriting")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/probcomp/Gen.jl"},"probcomp/Gen.jl: A general-purpose probabilistic programming system with programmable inference")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/LAMPSPUC"},"Laboratory of Applied Mathematical Programming and Statistics")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/biaslab"},"BIASlab")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/FRBNY-DSGE/DSGE.jl"},"FRBNY-DSGE/DSGE.jl: Solve and estimate Dynamic Stochastic General Equilibrium models (including the New York Fed DSGE)")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/StatisticalRethinkingJulia/StatisticalRethinking.jl"},"StatisticalRethinkingJulia/StatisticalRethinking.jl: Julia package with selected functions in the R package ",(0,r.kt)("inlineCode",{parentName:"a"},"rethinking"),". Used in the SR2... projects.")),(0,r.kt)("p",null,"Python:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/pymc-devs/pymc"},"pymc-devs/pymc: Probabilistic Programming in Python: Bayesian Modeling and Probabilistic Machine Learning with Aesara")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/pints-team/pints"},"pints-team/pints: Probabilistic Inference on Noisy Time Series")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/pyro-ppl/pyro"},"pyro-ppl/pyro: Deep universal probabilistic programming with Python and PyTorch")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/pyro-ppl/numpyro"},"pyro-ppl/numpyro: Probabilistic programming with NumPy powered by JAX for autograd and JIT compilation to GPU/TPU/CPU.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/blackjax-devs/blackjax"},"blackjax-devs/blackjax: BlackJAX is a sampling library designed for ease of use, speed and modularity.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/tensorflow/probability"},"tensorflow/probability: Probabilistic reasoning and statistical analysis in TensorFlow")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/google/edward2"},"google/edward2: A simple probabilistic programming language.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/thu-ml/zhusuan"},"thu-ml/zhusuan: A probabilistic programming library for Bayesian deep learning, generative models, based on Tensorflow")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/jmschrei/pomegranate"},"jmschrei/pomegranate: Fast, flexible and easy to use probabilistic modelling in Python.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/csynbiosysIBioEUoE/BOMBs.jl"},"csynbiosysIBioEUoE/BOMBs.jl: Repository for the Julia BOMBS package")),(0,r.kt)("h3",{id:"341-mcmc"},(0,r.kt)("span",{id:"head31"},"3.4.1. MCMC")),(0,r.kt)("p",null,"Methods like HMC, SGLD are Covered by above-mentioned packages."),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mauro3/KissMCMC.jl"},"mauro3/KissMCMC.jl: Keep it simple, stupid, MCMC")),(0,r.kt)("p",null,"Nice",(0,r.kt)("a",{parentName:"p",href:"https://github.com/scheidan/BarkerMCMC.jl"},"scheidan/BarkerMCMC.jl: gradient based MCMC sampler")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/BigBayes/SGMCMC.jl"},"BigBayes/SGMCMC.jl: Stochastic Gradient Markov Chain Monte Carlo and Optimisation")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/tpapp/DynamicHMC.jl"},"tpapp/DynamicHMC.jl: Implementation of robust dynamic Hamiltonian Monte Carlo methods (NUTS) in Julia.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/madsjulia/AffineInvariantMCMC.jl"},"madsjulia/AffineInvariantMCMC.jl: Affine Invariant Markov Chain Monte Carlo (MCMC) Ensemble sampler")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/TuringLang/EllipticalSliceSampling.jl"},"TuringLang/EllipticalSliceSampling.jl: Julia implementation of elliptical slice sampling.")),(0,r.kt)("p",null,"Nested Sampling",(0,r.kt)("a",{parentName:"p",href:"https://github.com/TuringLang/NestedSamplers.jl"},"TuringLang/NestedSamplers.jl: Implementations of single and multi-ellipsoid nested sampling")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/bat/UltraNest.jl"},"bat/UltraNest.jl: Julia wrapper for UltraNest: advanced nested sampling for model comparison and parameter estimation")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/itsdfish/DifferentialEvolutionMCMC.jl"},"itsdfish/DifferentialEvolutionMCMC.jl: A Julia package for Differential Evolution MCMC")),(0,r.kt)("p",null,"Python:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/AdamCobb/hamiltorch"},"AdamCobb/hamiltorch: PyTorch-based library for Riemannian Manifold Hamiltonian Monte Carlo (RMHMC) and inference in Bayesian neural networks")),(0,r.kt)("p",null,"Review",(0,r.kt)("a",{parentName:"p",href:"https://github.com/jeremiecoullon/SGMCMCJax"},"jeremiecoullon/SGMCMCJax: Lightweight library of stochastic gradient MCMC algorithms written in JAX.")),(0,r.kt)("p",null,"Nested Sampling",(0,r.kt)("a",{parentName:"p",href:"https://github.com/joshspeagle/dynesty"},"joshspeagle/dynesty: Dynamic Nested Sampling package for computing Bayesian posteriors and evidences")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JohannesBuchner/UltraNest"},"JohannesBuchner/UltraNest: Fit and compare complex models reliably and rapidly. Advanced nested sampling.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/ruqizhang/csgmcmc"},"ruqizhang/csgmcmc: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/tensorflow/addons/issues/2469"},"Custom Tensorflow optimizer cSGLD (Stochastic Langevin Dynamics) in TF2: correct update ops? \xb7 Issue #2469 \xb7 tensorflow/addons")),(0,r.kt)("h3",{id:"342-approximate-bayesian-computation-abc"},(0,r.kt)("span",{id:"head32"},"3.4.2. Approximate Bayesian Computation (ABC)")),(0,r.kt)("p",null,"Also called likelihood free or simulation based methods"),(0,r.kt)("p",null,"Review",(0,r.kt)("a",{parentName:"p",href:"https://github.com/sbi-benchmark/sbibm"},"sbi-benchmark/sbibm: Simulation-based inference benchmark")),(0,r.kt)("p",null,"Julia: (few)"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaApproxInference"},"JuliaApproxInference")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/tanhevg/GpABC.jl"},"tanhevg/GpABC.jl")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/marcjwilliams1/ApproxBayes.jl"},"marcjwilliams1/ApproxBayes.jl: Approximate Bayesian Computation (ABC) algorithms for likelihood free inference in julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/francescoalemanno/KissABC.jl"},"francescoalemanno/KissABC.jl: Pure julia implementation of Multiple Affine Invariant Sampling for efficient Approximate Bayesian Computation")),(0,r.kt)("p",null,"Python:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/elfi-dev/elfi"},"elfi-dev/elfi: ELFI - Engine for Likelihood-Free Inference")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/eth-cscs/abcpy"},"eth-cscs/abcpy: ABCpy package")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/pints-team/pints"},"pints-team/pints: Probabilistic Inference on Noisy Time Series")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mackelab/sbi"},"mackelab/sbi: Simulation-based inference in PyTorch")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/ICB-DCM/pyABC"},"ICB-DCM/pyABC: distributed, likelihood-free inference")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/diyabc/abcranger"},"diyabc/abcranger: ABC random forests for model choice and parameter estimation, pure C++ implementation")),(0,r.kt)("h3",{id:"343-data-assimilation-smc-particles-filter"},(0,r.kt)("span",{id:"head33"},"3.4.3. Data Assimilation (SMC, particles filter)")),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/Alexander-Barth/DataAssim.jl"},"Alexander-Barth/DataAssim.jl: Implementation of various ensemble Kalman Filter data assimilation methods in Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/baggepinnen/LowLevelParticleFilters.jl"},"baggepinnen/LowLevelParticleFilters.jl: Simple particle/kalman filtering, smoothing and parameter estimation")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaGNSS/KalmanFilters.jl"},"JuliaGNSS/KalmanFilters.jl: Various Kalman Filters: KF, UKF, AUKF and their Square root variant")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/CliMA/EnsembleKalmanProcesses.jl"},"CliMA/EnsembleKalmanProcesses.jl: Implements Optimization and approximate uncertainty quantification algorithms, Ensemble Kalman Inversion, and Ensemble Kalman Processes.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/FRBNY-DSGE/StateSpaceRoutines.jl"},"FRBNY-DSGE/StateSpaceRoutines.jl: Package implementing common state-space routines.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/simsurace/FeedbackParticleFilters.jl"},"simsurace/FeedbackParticleFilters.jl: A Julia package that provides (feedback) particle filters for nonlinear stochastic filtering and data assimilation problems")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mjb3/DiscretePOMP.jl"},"mjb3/DiscretePOMP.jl: Bayesian inference for Discrete state-space Partially Observed Markov Processes in Julia. See the docs:")),(0,r.kt)("p",null,"Python:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/nchopin/particles"},"nchopin/particles: Sequential Monte Carlo in python")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/rlabbe/filterpy"},"rlabbe/filterpy: Python Kalman filtering and optimal estimation library. Implements Kalman filter, particle filter, Extended Kalman filter, Unscented Kalman filter, g-h (alpha-beta), least squares, H Infinity, smoothers, and more. Has companion book 'Kalman and Bayesian Filters in Python'.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/tingiskhan/pyfilter"},"tingiskhan/pyfilter: Particle filtering and sequential parameter inference in Python")),(0,r.kt)("h3",{id:"344-variational-inference"},(0,r.kt)("span",{id:"head34"},"3.4.4. Variational Inference")),(0,r.kt)("p",null,"SVGD",(0,r.kt)("a",{parentName:"p",href:"https://github.com/search?q=Stein+Variational+Gradient+Descent"},"Search \xb7 Stein Variational Gradient Descent"),"Also see pyro, Stein method part"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/Red-Portal/KLpqVI.jl"},"Red-Portal/KLpqVI.jl")),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/bat/MGVI.jl"},"bat/MGVI.jl: Metric Gaussian Variational Inference")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/TuringLang/AdvancedVI.jl"},"TuringLang/AdvancedVI.jl: A library for variational Bayesian methods in Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/ngiann/ApproximateVI.jl"},"ngiann/ApproximateVI.jl: Approximate variational inference in Julia")),(0,r.kt)("p",null,"Python:"),(0,r.kt)("h3",{id:"345-gaussion-non-gaussion-and-kernel"},(0,r.kt)("span",{id:"head35"},"3.4.5. Gaussion, non-Gaussion and Kernel")),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaGaussianProcesses"},"Gaussian Processes for Machine Learning in Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/LAMPSPUC"},"Laboratory of Applied Mathematical Programming and Statistics")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaRobotics"},"JuliaRobotics")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaStats/KernelDensity.jl"},"JuliaStats/KernelDensity.jl: Kernel density estimators for Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaRobotics/KernelDensityEstimate.jl"},"JuliaRobotics/KernelDensityEstimate.jl: Kernel Density Estimate with product approximation using multiscale Gibbs sampling")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/theogf/AugmentedGaussianProcesses.jl"},"theogf/AugmentedGaussianProcesses.jl: Gaussian Process package based on data augmentation, sparsity and natural gradients")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaGaussianProcesses/TemporalGPs.jl"},"JuliaGaussianProcesses/TemporalGPs.jl: Fast inference for Gaussian processes in problems involving time")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/aterenin/SparseGaussianProcesses.jl"},"aterenin/SparseGaussianProcesses.jl: A Julia implementation of sparse Gaussian processes via path-wise doubly stochastic variational inference.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/PieterjanRobbe/GaussianRandomFields.jl"},"PieterjanRobbe/GaussianRandomFields.jl: A package for Gaussian random field generation in Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaGaussianProcesses/Stheno.jl"},"JuliaGaussianProcesses/Stheno.jl: Probabilistic Programming with Gaussian processes in Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/STOR-i/GaussianProcesses.jl"},"STOR-i/GaussianProcesses.jl: A Julia package for Gaussian Processes")),(0,r.kt)("p",null,"Python:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/cornellius-gp/gpytorch"},"cornellius-gp/gpytorch: A highly efficient and modular implementation of Gaussian Processes in PyTorch")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/GPflow/GPflow"},"GPflow/GPflow: Gaussian processes in TensorFlow")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/SheffieldML/GPy"},"SheffieldML/GPy: Gaussian processes framework in python")),(0,r.kt)("h3",{id:"346-bayesian-optimization"},(0,r.kt)("span",{id:"head36"},"3.4.6. Bayesian Optimization")),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/SciML/Surrogates.jl"},"SciML/Surrogates.jl: Surrogate modeling and optimization for scientific machine learning (SciML)")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/jbrea/BayesianOptimization.jl"},"jbrea/BayesianOptimization.jl: Bayesian optimization for Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/baggepinnen/Hyperopt.jl"},"baggepinnen/Hyperopt.jl: Hyperparameter optimization in Julia.")),(0,r.kt)("p",null,"Python:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/fmfn/BayesianOptimization"},"fmfn/BayesianOptimization: A Python implementation of global optimization with gaussian processes.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/pytorch/botorch"},"pytorch/botorch: Bayesian optimization in PyTorch")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/optuna/optuna"},"optuna/optuna: A hyperparameter optimization framework")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/huawei-noah/HEBO"},"huawei-noah/HEBO: Bayesian optimisation library developped by Huawei Noah's Ark Library")),(0,r.kt)("h3",{id:"347-information-theory"},(0,r.kt)("span",{id:"head37"},"3.4.7. Information theory")),(0,r.kt)("p",null,"Julia:\nentropy and kldivengence for distributions or vectors can be seen in Distributions.jl"),(0,r.kt)("p",null,"KL divergence for functions",(0,r.kt)("a",{parentName:"p",href:"https://github.com/RafaelArutjunjan/InformationGeometry.jl"},"RafaelArutjunjan/InformationGeometry.jl: Methods for computational information geometry")),(0,r.kt)("p",null,"not maintained",(0,r.kt)("a",{parentName:"p",href:"https://github.com/kzahedi/Shannon.jl"},"kzahedi/Shannon.jl: Entropy, Mutual Information, KL-Divergence related to Shannon's information theory and functions to binarize data")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/gragusa/Divergences.jl"},"gragusa/Divergences.jl: A Julia package for evaluation of divergences between distributions")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/Tchanders/InformationMeasures.jl"},"Tchanders/InformationMeasures.jl: Entropy, mutual information and higher order measures from information theory, with various estimators and discretisation methods.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaDynamics/TransferEntropy.jl"},"JuliaDynamics/TransferEntropy.jl: Transfer entropy (conditional mutual information) estimators for the Julia language")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/cynddl/Discreet.jl"},"cynddl/Discreet.jl: A Julia package to estimate discrete entropy and mutual information")),(0,r.kt)("h3",{id:"348-uncertainty"},(0,r.kt)("span",{id:"head38"},"3.4.8. Uncertainty")),(0,r.kt)("p",null,"Uncertainty propogation"),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaPhysics/Measurements.jl"},"JuliaPhysics/Measurements.jl: Error propagation calculator and library for physical measurements. It supports real and complex numbers with uncertainty, arbitrary precision calculations, operations with arrays, and numerical integration.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/baggepinnen/MonteCarloMeasurements.jl"},"baggepinnen/MonteCarloMeasurements.jl: Propagation of distributions by Monte-Carlo sampling: Real number types with uncertainty represented by samples.")),(0,r.kt)("p",null,"Review",(0,r.kt)("a",{parentName:"p",href:"https://book.sciml.ai/notes/19/"},"Uncertainty Programming, Generalized Uncertainty Quantification")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/AnderGray/MomentArithmetic.jl"},"AnderGray/MomentArithmetic.jl: Rigorous moment propagation with partial information about moments and dependencies in Julia")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mschauer/Mitosis.jl"},"mschauer/Mitosis.jl: Automatic probabilistic programming for scientific machine learning and dynamical models")),(0,r.kt)("p",null,"Good",(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaReach/RangeEnclosures.jl"},"JuliaReach/RangeEnclosures.jl: A Julia package to compute range enclosures of real-valued functions.")),(0,r.kt)("p",null,"Python"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/uncertainty-toolbox/uncertainty-toolbox"},"uncertainty-toolbox/uncertainty-toolbox: A python toolbox for predictive uncertainty quantification, calibration, metrics, and visualization")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/pyro-ppl/funsor"},"pyro-ppl/funsor: Functional tensors for probabilistic programming")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/lebigot/uncertainties/"},'lebigot/uncertainties: Transparent calculations with uncertainties on the quantities involved (aka "error propagation"); calculation of derivatives.')),(0,r.kt)("h3",{id:"349-casual"},(0,r.kt)("span",{id:"head39"},"3.4.9. Casual")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/zenna/Omega.jl"},"zenna/Omega.jl: Causal, Higher-Order, Probabilistic Programming")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mschauer/CausalInference.jl"},"mschauer/CausalInference.jl: Causal inference, graphical models and structure learning with the PC algorithm.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/JuliaDynamics/CausalityTools.jl"},"JuliaDynamics/CausalityTools.jl: Algorithms for causal inference and the detection of dynamical coupling from time series, and for approximation of the transfer operator and invariant measures.")),(0,r.kt)("p",null,"python"),(0,r.kt)("p",null,"Review: ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/rguo12/awesome-causality-algorithms"},"rguo12/awesome-causality-algorithms: An index of algorithms for learning causality with data")),(0,r.kt)("h3",{id:"3410-sampling"},(0,r.kt)("span",{id:"head40"},"3.4.10. Sampling")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/MrUrq/LatinHypercubeSampling.jl"},"MrUrq/LatinHypercubeSampling.jl: Julia package for the creation of optimised Latin Hypercube Sampling Plans")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/SciML/QuasiMonteCarlo.jl"},"SciML/QuasiMonteCarlo.jl: Lightweight and easy generation of quasi-Monte Carlo sequences with a ton of different methods on one API for easy parameter exploration in scientific machine learning (SciML)")),(0,r.kt)("h3",{id:"3411-message-passing"},"3.4.11 Message Passing"),(0,r.kt)("p",null,"Julia:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/biaslab/ReactiveMP.jl"},"biaslab/ReactiveMP.jl: Julia package for automatic Bayesian inference on a factor graph with reactive message passing")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/biaslab/ForneyLab.jl"},"biaslab/ForneyLab.jl: Julia package for automatically generating Bayesian inference algorithms through message passing on Forney-style factor graphs.")))}h.isMDXComponent=!0}}]);