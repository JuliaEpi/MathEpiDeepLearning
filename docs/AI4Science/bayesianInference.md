---
sidebar_position: 6
---

## <span id="head30">3.4. Bayesian Inference</span>

[StatisticalRethinkingJulia](https://github.com/StatisticalRethinkingJulia)

[StanJulia](https://github.com/StanJulia)

Julia:

[The Turing Language](https://github.com/TuringLang)

[cscherrer/Soss.jl: Probabilistic programming via source rewriting](https://github.com/cscherrer/Soss.jl)

[probcomp/Gen.jl: A general-purpose probabilistic programming system with programmable inference](https://github.com/probcomp/Gen.jl)

[Laboratory of Applied Mathematical Programming and Statistics](https://github.com/LAMPSPUC)

[BIASlab](https://github.com/biaslab)

[FRBNY-DSGE/DSGE.jl: Solve and estimate Dynamic Stochastic General Equilibrium models (including the New York Fed DSGE)](https://github.com/FRBNY-DSGE/DSGE.jl)

[StatisticalRethinkingJulia/StatisticalRethinking.jl: Julia package with selected functions in the R package `rethinking`. Used in the SR2... projects.](https://github.com/StatisticalRethinkingJulia/StatisticalRethinking.jl)

Python:

[pymc-devs/pymc: Probabilistic Programming in Python: Bayesian Modeling and Probabilistic Machine Learning with Aesara](https://github.com/pymc-devs/pymc)

[pints-team/pints: Probabilistic Inference on Noisy Time Series](https://github.com/pints-team/pints)

[pyro-ppl/pyro: Deep universal probabilistic programming with Python and PyTorch](https://github.com/pyro-ppl/pyro)

[pyro-ppl/numpyro: Probabilistic programming with NumPy powered by JAX for autograd and JIT compilation to GPU/TPU/CPU.](https://github.com/pyro-ppl/numpyro)

[blackjax-devs/blackjax: BlackJAX is a sampling library designed for ease of use, speed and modularity.](https://github.com/blackjax-devs/blackjax)

[tensorflow/probability: Probabilistic reasoning and statistical analysis in TensorFlow](https://github.com/tensorflow/probability)

[google/edward2: A simple probabilistic programming language.](https://github.com/google/edward2)

[thu-ml/zhusuan: A probabilistic programming library for Bayesian deep learning, generative models, based on Tensorflow](https://github.com/thu-ml/zhusuan)

[jmschrei/pomegranate: Fast, flexible and easy to use probabilistic modelling in Python.](https://github.com/jmschrei/pomegranate)

[csynbiosysIBioEUoE/BOMBs.jl: Repository for the Julia BOMBS package](https://github.com/csynbiosysIBioEUoE/BOMBs.jl)

### <span id="head31">3.4.1. MCMC</span>

Methods like HMC, SGLD are Covered by above-mentioned packages.

Julia:

[mauro3/KissMCMC.jl: Keep it simple, stupid, MCMC](https://github.com/mauro3/KissMCMC.jl)

Nice[scheidan/BarkerMCMC.jl: gradient based MCMC sampler](https://github.com/scheidan/BarkerMCMC.jl)

[BigBayes/SGMCMC.jl: Stochastic Gradient Markov Chain Monte Carlo and Optimisation](https://github.com/BigBayes/SGMCMC.jl)

[tpapp/DynamicHMC.jl: Implementation of robust dynamic Hamiltonian Monte Carlo methods (NUTS) in Julia.](https://github.com/tpapp/DynamicHMC.jl)

[madsjulia/AffineInvariantMCMC.jl: Affine Invariant Markov Chain Monte Carlo (MCMC) Ensemble sampler](https://github.com/madsjulia/AffineInvariantMCMC.jl)

[TuringLang/EllipticalSliceSampling.jl: Julia implementation of elliptical slice sampling.](https://github.com/TuringLang/EllipticalSliceSampling.jl)

Nested Sampling[TuringLang/NestedSamplers.jl: Implementations of single and multi-ellipsoid nested sampling](https://github.com/TuringLang/NestedSamplers.jl)

[bat/UltraNest.jl: Julia wrapper for UltraNest: advanced nested sampling for model comparison and parameter estimation](https://github.com/bat/UltraNest.jl)

[itsdfish/DifferentialEvolutionMCMC.jl: A Julia package for Differential Evolution MCMC](https://github.com/itsdfish/DifferentialEvolutionMCMC.jl)

Python:

[AdamCobb/hamiltorch: PyTorch-based library for Riemannian Manifold Hamiltonian Monte Carlo (RMHMC) and inference in Bayesian neural networks](https://github.com/AdamCobb/hamiltorch)

Review[jeremiecoullon/SGMCMCJax: Lightweight library of stochastic gradient MCMC algorithms written in JAX.](https://github.com/jeremiecoullon/SGMCMCJax)

Nested Sampling[joshspeagle/dynesty: Dynamic Nested Sampling package for computing Bayesian posteriors and evidences](https://github.com/joshspeagle/dynesty)

[JohannesBuchner/UltraNest: Fit and compare complex models reliably and rapidly. Advanced nested sampling.](https://github.com/JohannesBuchner/UltraNest)

[ruqizhang/csgmcmc: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning](https://github.com/ruqizhang/csgmcmc)

[Custom Tensorflow optimizer cSGLD (Stochastic Langevin Dynamics) in TF2: correct update ops? · Issue #2469 · tensorflow/addons](https://github.com/tensorflow/addons/issues/2469)

### <span id="head32">3.4.2. Approximate Bayesian Computation (ABC)</span>

Also called likelihood free or simulation based methods

Review[sbi-benchmark/sbibm: Simulation-based inference benchmark](https://github.com/sbi-benchmark/sbibm)

Julia: (few)

[JuliaApproxInference](https://github.com/JuliaApproxInference)

[tanhevg/GpABC.jl](https://github.com/tanhevg/GpABC.jl)

[marcjwilliams1/ApproxBayes.jl: Approximate Bayesian Computation (ABC) algorithms for likelihood free inference in julia](https://github.com/marcjwilliams1/ApproxBayes.jl)

[francescoalemanno/KissABC.jl: Pure julia implementation of Multiple Affine Invariant Sampling for efficient Approximate Bayesian Computation](https://github.com/francescoalemanno/KissABC.jl)

Python:

[elfi-dev/elfi: ELFI - Engine for Likelihood-Free Inference](https://github.com/elfi-dev/elfi)

[eth-cscs/abcpy: ABCpy package](https://github.com/eth-cscs/abcpy)

[pints-team/pints: Probabilistic Inference on Noisy Time Series](https://github.com/pints-team/pints)

[mackelab/sbi: Simulation-based inference in PyTorch](https://github.com/mackelab/sbi)

[ICB-DCM/pyABC: distributed, likelihood-free inference](https://github.com/ICB-DCM/pyABC)

[diyabc/abcranger: ABC random forests for model choice and parameter estimation, pure C++ implementation](https://github.com/diyabc/abcranger)

### <span id="head33">3.4.3. Data Assimilation (SMC, particles filter)</span>

Julia:

[Alexander-Barth/DataAssim.jl: Implementation of various ensemble Kalman Filter data assimilation methods in Julia](https://github.com/Alexander-Barth/DataAssim.jl)

[baggepinnen/LowLevelParticleFilters.jl: Simple particle/kalman filtering, smoothing and parameter estimation](https://github.com/baggepinnen/LowLevelParticleFilters.jl)

[JuliaGNSS/KalmanFilters.jl: Various Kalman Filters: KF, UKF, AUKF and their Square root variant](https://github.com/JuliaGNSS/KalmanFilters.jl)

[CliMA/EnsembleKalmanProcesses.jl: Implements Optimization and approximate uncertainty quantification algorithms, Ensemble Kalman Inversion, and Ensemble Kalman Processes.](https://github.com/CliMA/EnsembleKalmanProcesses.jl)

[FRBNY-DSGE/StateSpaceRoutines.jl: Package implementing common state-space routines.](https://github.com/FRBNY-DSGE/StateSpaceRoutines.jl)

[simsurace/FeedbackParticleFilters.jl: A Julia package that provides (feedback) particle filters for nonlinear stochastic filtering and data assimilation problems](https://github.com/simsurace/FeedbackParticleFilters.jl)

[mjb3/DiscretePOMP.jl: Bayesian inference for Discrete state-space Partially Observed Markov Processes in Julia. See the docs:](https://github.com/mjb3/DiscretePOMP.jl)

Python:

[nchopin/particles: Sequential Monte Carlo in python](https://github.com/nchopin/particles)

[rlabbe/filterpy: Python Kalman filtering and optimal estimation library. Implements Kalman filter, particle filter, Extended Kalman filter, Unscented Kalman filter, g-h (alpha-beta), least squares, H Infinity, smoothers, and more. Has companion book 'Kalman and Bayesian Filters in Python'.](https://github.com/rlabbe/filterpy)

[tingiskhan/pyfilter: Particle filtering and sequential parameter inference in Python](https://github.com/tingiskhan/pyfilter)

### <span id="head34">3.4.4. Variational Inference</span>

SVGD[Search · Stein Variational Gradient Descent](https://github.com/search?q=Stein+Variational+Gradient+Descent)Also see pyro, Stein method part

[Red-Portal/KLpqVI.jl](https://github.com/Red-Portal/KLpqVI.jl)

Julia:

[bat/MGVI.jl: Metric Gaussian Variational Inference](https://github.com/bat/MGVI.jl)

[TuringLang/AdvancedVI.jl: A library for variational Bayesian methods in Julia](https://github.com/TuringLang/AdvancedVI.jl)

[ngiann/ApproximateVI.jl: Approximate variational inference in Julia](https://github.com/ngiann/ApproximateVI.jl)

Python:

### <span id="head35">3.4.5. Gaussion, non-Gaussion and Kernel</span>

Julia:

[Gaussian Processes for Machine Learning in Julia](https://github.com/JuliaGaussianProcesses)

[Laboratory of Applied Mathematical Programming and Statistics](https://github.com/LAMPSPUC)

[JuliaRobotics](https://github.com/JuliaRobotics)

[JuliaStats/KernelDensity.jl: Kernel density estimators for Julia](https://github.com/JuliaStats/KernelDensity.jl)

[JuliaRobotics/KernelDensityEstimate.jl: Kernel Density Estimate with product approximation using multiscale Gibbs sampling](https://github.com/JuliaRobotics/KernelDensityEstimate.jl)

[theogf/AugmentedGaussianProcesses.jl: Gaussian Process package based on data augmentation, sparsity and natural gradients](https://github.com/theogf/AugmentedGaussianProcesses.jl)

[JuliaGaussianProcesses/TemporalGPs.jl: Fast inference for Gaussian processes in problems involving time](https://github.com/JuliaGaussianProcesses/TemporalGPs.jl)

[aterenin/SparseGaussianProcesses.jl: A Julia implementation of sparse Gaussian processes via path-wise doubly stochastic variational inference.](https://github.com/aterenin/SparseGaussianProcesses.jl)

[PieterjanRobbe/GaussianRandomFields.jl: A package for Gaussian random field generation in Julia](https://github.com/PieterjanRobbe/GaussianRandomFields.jl)

[JuliaGaussianProcesses/Stheno.jl: Probabilistic Programming with Gaussian processes in Julia](https://github.com/JuliaGaussianProcesses/Stheno.jl)

[STOR-i/GaussianProcesses.jl: A Julia package for Gaussian Processes](https://github.com/STOR-i/GaussianProcesses.jl)

Python:

[cornellius-gp/gpytorch: A highly efficient and modular implementation of Gaussian Processes in PyTorch](https://github.com/cornellius-gp/gpytorch)

[GPflow/GPflow: Gaussian processes in TensorFlow](https://github.com/GPflow/GPflow)

[SheffieldML/GPy: Gaussian processes framework in python](https://github.com/SheffieldML/GPy)

### <span id="head36">3.4.6. Bayesian Optimization</span>

Julia:

[SciML/Surrogates.jl: Surrogate modeling and optimization for scientific machine learning (SciML)](https://github.com/SciML/Surrogates.jl)

[jbrea/BayesianOptimization.jl: Bayesian optimization for Julia](https://github.com/jbrea/BayesianOptimization.jl)

[baggepinnen/Hyperopt.jl: Hyperparameter optimization in Julia.](https://github.com/baggepinnen/Hyperopt.jl)

Python:

[fmfn/BayesianOptimization: A Python implementation of global optimization with gaussian processes.](https://github.com/fmfn/BayesianOptimization)

[pytorch/botorch: Bayesian optimization in PyTorch](https://github.com/pytorch/botorch)

[optuna/optuna: A hyperparameter optimization framework](https://github.com/optuna/optuna)

[huawei-noah/HEBO: Bayesian optimisation library developped by Huawei Noah's Ark Library](https://github.com/huawei-noah/HEBO)

### <span id="head37">3.4.7. Information theory</span>

Julia:
entropy and kldivengence for distributions or vectors can be seen in Distributions.jl

KL divergence for functions[RafaelArutjunjan/InformationGeometry.jl: Methods for computational information geometry](https://github.com/RafaelArutjunjan/InformationGeometry.jl)

not maintained[kzahedi/Shannon.jl: Entropy, Mutual Information, KL-Divergence related to Shannon's information theory and functions to binarize data](https://github.com/kzahedi/Shannon.jl)

[gragusa/Divergences.jl: A Julia package for evaluation of divergences between distributions](https://github.com/gragusa/Divergences.jl)

[Tchanders/InformationMeasures.jl: Entropy, mutual information and higher order measures from information theory, with various estimators and discretisation methods.](https://github.com/Tchanders/InformationMeasures.jl)

[JuliaDynamics/TransferEntropy.jl: Transfer entropy (conditional mutual information) estimators for the Julia language](https://github.com/JuliaDynamics/TransferEntropy.jl)

[cynddl/Discreet.jl: A Julia package to estimate discrete entropy and mutual information](https://github.com/cynddl/Discreet.jl)

### <span id="head38">3.4.8. Uncertainty</span>

Uncertainty propogation

Julia:

[JuliaPhysics/Measurements.jl: Error propagation calculator and library for physical measurements. It supports real and complex numbers with uncertainty, arbitrary precision calculations, operations with arrays, and numerical integration.](https://github.com/JuliaPhysics/Measurements.jl)

[baggepinnen/MonteCarloMeasurements.jl: Propagation of distributions by Monte-Carlo sampling: Real number types with uncertainty represented by samples.](https://github.com/baggepinnen/MonteCarloMeasurements.jl)

Review[Uncertainty Programming, Generalized Uncertainty Quantification](https://book.sciml.ai/notes/19/)

[AnderGray/MomentArithmetic.jl: Rigorous moment propagation with partial information about moments and dependencies in Julia](https://github.com/AnderGray/MomentArithmetic.jl)

[mschauer/Mitosis.jl: Automatic probabilistic programming for scientific machine learning and dynamical models](https://github.com/mschauer/Mitosis.jl)

Good[JuliaReach/RangeEnclosures.jl: A Julia package to compute range enclosures of real-valued functions.](https://github.com/JuliaReach/RangeEnclosures.jl)

Python

[uncertainty-toolbox/uncertainty-toolbox: A python toolbox for predictive uncertainty quantification, calibration, metrics, and visualization](https://github.com/uncertainty-toolbox/uncertainty-toolbox)

[pyro-ppl/funsor: Functional tensors for probabilistic programming](https://github.com/pyro-ppl/funsor)

[lebigot/uncertainties: Transparent calculations with uncertainties on the quantities involved (aka "error propagation"); calculation of derivatives.](https://github.com/lebigot/uncertainties/)

### <span id="head39">3.4.9. Casual</span>

[zenna/Omega.jl: Causal, Higher-Order, Probabilistic Programming](https://github.com/zenna/Omega.jl)

[mschauer/CausalInference.jl: Causal inference, graphical models and structure learning with the PC algorithm.](https://github.com/mschauer/CausalInference.jl)

[JuliaDynamics/CausalityTools.jl: Algorithms for causal inference and the detection of dynamical coupling from time series, and for approximation of the transfer operator and invariant measures.](https://github.com/JuliaDynamics/CausalityTools.jl)

python

Review: [rguo12/awesome-causality-algorithms: An index of algorithms for learning causality with data](https://github.com/rguo12/awesome-causality-algorithms)

### <span id="head40">3.4.10. Sampling</span>

[MrUrq/LatinHypercubeSampling.jl: Julia package for the creation of optimised Latin Hypercube Sampling Plans](https://github.com/MrUrq/LatinHypercubeSampling.jl)

[SciML/QuasiMonteCarlo.jl: Lightweight and easy generation of quasi-Monte Carlo sequences with a ton of different methods on one API for easy parameter exploration in scientific machine learning (SciML)](https://github.com/SciML/QuasiMonteCarlo.jl)

### 3.4.11 Message Passing

Julia:

[biaslab/ReactiveMP.jl: Julia package for automatic Bayesian inference on a factor graph with reactive message passing](https://github.com/biaslab/ReactiveMP.jl)

[biaslab/ForneyLab.jl: Julia package for automatically generating Bayesian inference algorithms through message passing on Forney-style factor graphs.](https://github.com/biaslab/ForneyLab.jl)
